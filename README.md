# Automated Motion Canvas Video Pipeline

This project converts a topic into a Motion Canvas scene file using a structured pipeline:

`Idea -> LLM -> VideoSpec JSON -> Director refinement -> Motion Canvas scene code`

The single source of truth is the validated `VideoSpec` object.

## Current Process (Exact)

1. Run generation CLI.
2. `scriptAgent` asks the model for strict JSON (`json_schema` response format).
3. Raw LLM `VideoSpec` is saved to `output/videospec.llm.json`.
4. `structuredOutput` parses + validates with Zod (`videoSpecSchema`).
5. `directorAgent` enforces deterministic pacing and timing rules.
6. `motionCanvasAgent` converts to `renderSpec`.
7. `renderer` writes `src/scenes/generatedPipelineScene.tsx`.
8. Motion Canvas project (`src/project.ts`) imports and uses `generatedPipelineScene`.

## Important Clarification

You asked whether code is needed after `renderSpec`.

No manual code is needed.

`src/scenes/generatedPipelineScene.tsx` already contains:
- `const renderSpec = {...}` data
- executable scene generator code below it (`makeScene2D(...)`) that loops scenes/elements and applies animations

That runtime code is auto-generated by `src/motion/renderer.ts`.

## Setup

1. Install dependencies:
```bash
npm install
```

2. Configure environment:
```bash
cp .env.example .env
```
Set:
- `OPENAI_API_KEY=...`
- `OPENAI_MODEL=gpt-5.2` (or omit to use default)

## Generate Scene Code

Default example topic:
```bash
npm run generate
```

Custom topic/audience/duration:
```bash
npm run generate -- \
  --topic "How systems scale to 1 million users" \
  --audience "beginner" \
  --duration 60 \
  --model gpt-5.2 \
  --output src/scenes/generatedPipelineScene.tsx \
  --llm-spec-output output/videospec.llm.json
```

Output:
- Generated scene file path printed in terminal.
- Usually `src/scenes/generatedPipelineScene.tsx`.
- Raw LLM output spec is saved to `output/videospec.llm.json` by default.

## Create Video (Render)

1. Start Motion Canvas studio:
```bash
npm run studio
```

2. Open the project in browser.
3. Ensure `src/project.ts` includes `generatedPipelineScene` (already wired).
4. Use the Motion Canvas UI render/export action to render MP4/GIF.

## Key Files

- Pipeline orchestrator: `src/pipeline/generateVideo.ts`
- Prompt: `src/llm/prompts.ts`
- Structured output + retries: `src/llm/structuredOutput.ts`
- OpenAI client: `src/llm/openaiClient.ts`
- VideoSpec schema + strict response format: `src/schema/videoSpec.schema.ts`
- Scene template writer: `src/motion/renderer.ts`
- Generated scene: `src/scenes/generatedPipelineScene.tsx`
- Motion Canvas project entry: `src/project.ts`

## Troubleshooting

- `Invalid schema for response_format`: check `videoSpecResponseFormat` in `src/schema/videoSpec.schema.ts`.
- Parse/validation failures: inspect logs from `structuredOutput` for issue paths.
- Network errors (`EAI_AGAIN`): DNS/network issue while calling OpenAI API.
